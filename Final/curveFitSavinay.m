% Pattern recognition and Machine Learning (EE552)
% Project 1 - Regression Models
%Code written by: Savinay Nagendra (sxn265)

%Functions used: 
% 1. X = hypothesis func(data,order)
% This function is going to generate a (N X order+1) data matrix, where N
% is the length of data.
% 2. [x,y,t] = generateDate(mu,sigma,npts) 
% This function is going to generate the data points x, desired values without gaussian noise y
% and the target  t for a given mean mu, standard deviation sigma and the
% total number of data points npts.

% The code is divied into 4 sections. It is generalized. So, you can change
% the order vector, the number of points, lambda, beta and alpha values
% according to need.
%% Regression for Energy Minimization, without regularization
% data points have been generated by adding a Random Gaussian Noise to a sinusoid.
clc;
clear all;
close all;
npts = 50;
[x,y,t] = generateData(0,0.3,npts);  % generates the data with mean 0 and std 0.3
addpath export_fig/
% order vector can be of any length.
% Enter the desired order magnitudes in the below vector.
order = [0 1 3 6 9 15];
% each of the outputs corresponding to a particular order are stored in cell arrays
for l = 1:length(order)
    X{l} = hypothesis_func(x,order(l));
    W_star{l} = zeros(order(l)+1,1);
    W_star{l} = (X{l}'*X{l})\(X{l}'*t');
    Y_star{l} = X{l}*W_star{l};
    f1 = figure(l);
    %ploting data and fitted curves
    plot(x,Y_star{l},'b-','LineWidth',1.5);
    hold on;
    plot(x,y,'g-','LineWidth',1.5);
    hold on;
    plot(x,t,'ro','MarkerSize',8,'LineWidth',1.5);
    hold on; 
    grid on;
    set(gca,'FontWeight','bold','LineWidth',1.5)
    xlabel('x')
    ylabel('t')
    title(['Regression without regularization, poly order = ', num2str(order(l))] );
    legend(['curve fit with order =',num2str(order(l))],'sinusoid without gaussian noise','training data points');
    saveas(f1,sprintf('EMwithoutReg%d',l),'png')
    error{l} = 0.5*(X{l}*W_star{l} - t')'*(X{l}*W_star{l} - t');
    RMS_error{l} = sqrt(2*error{l}/length(x));
    % Test data 
    npts_test = 20;
    Test_x = linspace(1,2*pi,npts_test);
    Test_t = sin(0.5*Test_x) + 0.3*randn(1,npts_test);
    Y_star_test{l} = Test_x(1:length(W_star{l}))*W_star{l};
    error_test{l} = 0.5*(Y_star_test{l} - Test_t')'*(Y_star_test{l} - Test_t');
    RMS_error_test{l} = sqrt(2*error_test{l}/length(Test_x));
end
rms_vector = cell2mat(RMS_error);
rms_vector_test = cell2mat(RMS_error_test);
%plotting errors
f1 = figure;
plot(order,rms_vector,'b-','LineWidth',2);
hold on;
plot(order,rms_vector_test,'r-','LineWidth',2);
title('RMS error of test and train vs Order (Without Regularization)');
xlabel('Order');
ylabel('RMS error');
legend('training error','testing error');
saveas(f1,'RMSerrorwithoutReg','png');
%% Regression for Energy Minimization, with regularization
clc;
clear all;
close all;
npts = 50;
% generates the data points
[x,y,t] = generateData(0,0.3,npts);
% order vector can be of any length.
% Enter the desired order magnitudes in the below vector.
order = [0 1 3 6 9 15];
% lamda vector can be of any length.
% Enter the desired lamda magnitudes in the below vector.
lamda = [0.01 0.1 1];
% each of the outputs corresponding to a particular order and particular lamda are stored in cell arrays

for i = 1:length(lamda)
    for l = 1:length(order)
        X{l,i} = hypothesis_func(x,order(l));
        W_star{l,i} = zeros(order(l)+1,1);
        a = eye(order(l));
        lamda_matrix{l,i} = lamda(i)*[zeros(1,order(l)+1) ; zeros(order(l),1),a];
        W_star{l,i} = (X{l,i}'*X{l,i} + lamda_matrix{l,i})\(X{l,i}'*t');
        Y_star{l,i} = X{l,i}*W_star{l,i};
        f2 = figure(l);
        %plotting data values and fitted curves
        plot(x,y,'g-','LineWidth',1.5);
        hold on;
        plot(x,Y_star{l,i},'b-','LineWidth',1.5);
        hold on;
        plot(x,t,'ro','MarkerSize',8,'LineWidth',1.5);
        hold off; 
        grid on;
        set(gca,'FontWeight','bold','LineWidth',1.5);
        xlabel('x');
        ylabel('t');
        title(['order = ', num2str(order(l)),'lamda = ',num2str(lamda(i))]);
        legend('sinusoid without gaussian noise',['curve fit with order =',num2str(order(l))],'training data points');
        saveas(f2,sprintf('EMwithReg%d%d',l,i),'png');
        
        error{l,i} = 0.5*((X{l,i}*W_star{l,i} - t')'*(X{l,i}*W_star{l,i} - t') + lamda(i)*W_star{l,i}'*W_star{l,i});
        RMS_error{l,i} = sqrt(2*error{l,i}/length(x));
        % Test data
        npts_test = 20;
        Test_x = linspace(1,2*pi,npts_test);
        Test_t = sin(0.5*Test_x) + 0.3*randn(1,npts_test);
        Y_star_test{l,i} = Test_x(1:length(W_star{l,i}))*W_star{l,i};
        error_test{l,i} = 0.5*(Y_star_test{l,i} - Test_t')'*(Y_star_test{l,i} - Test_t');
        RMS_error_test{l,i} = sqrt(2*error_test{l,i}/length(Test_x));
        
    end
end
rms_vector = cell2mat(RMS_error);
rms_vector_test = cell2mat(RMS_error_test);
%plotting errors
for i = 1:length(lamda)
    f = figure;
    plot(order,rms_vector(:,i),'b-','LineWidth',1.5);
    hold on;
    plot(order,rms_vector_test(:,i),'r-','LineWidth',1.5);
    title(['RMS error for test and train vs Order for lamda = ',num2str(lamda(i))]);
    legend('Training error','Testing error');
    xlabel('Order');
    ylabel('RMS error');
    saveas(f,'RMSerrorwithReg','png');
end


    
%% Regression with MLE

clc;
clear all;
close all;
npts = 50;
%generates the data points
[x,y,t] = generateData(0,0.3,npts);
% order vector can be of any length.
% Enter the desired order magnitudes in the below vector.
order = [0 1 3 6 9 15];

% each of the outputs corresponding to a particular order are stored in cell arrays

for l = 1:length(order)
    X{l} = hypothesis_func(x,order(l));
    W_star{l} = zeros(order(l)+1,1);
    W_star{l} = (X{l}'*X{l})\(X{l}'*t');
    mean_ML{l} = X{l}*W_star{l};
    
    beta_ML = 1/(((X{l}*W_star{l} - t')'*(X{l}*W_star{l} - t'))/length(x));
    b = ones(length(x),1);
    f3 = figure(l);
    % plotting data values, fitted curves and the shared area of certainty.
    h = shadedErrorBar(x,mean_ML{l}, sqrt((1/beta_ML)*b),{'b-','color','b','LineWidth',1.5},0);
    hold on;
    plot(x,t,'ro','MarkerSize',8,'LineWidth',1.5);
    hold off; 
    grid on;
    set(gca,'FontWeight','bold','LineWidth',1.5)
    xlabel('x')
    ylabel('t')
    title(['Regression without MLE, poly order = ', num2str(order(l))]);

    saveas(f3,sprintf('MLE%d',l),'png');
    % Test Data
    npts_test = 20;
    error{l} = 0.5*(X{l}*W_star{l} - t')'*(X{l}*W_star{l} - t');
    RMS_error{l} = sqrt(2*error{l}/length(x));
    Test_x = linspace(1,2*pi,npts_test);
    Test_t = sin(0.5*Test_x) + 0.3*randn(1,npts_test);
    Y_star_test{l} = Test_x(1:length(W_star{l}))*W_star{l};
    error_test{l} = 0.5*(Y_star_test{l} - Test_t')'*(Y_star_test{l} - Test_t');
    RMS_error_test{l} = sqrt(2*error_test{l}/length(Test_x));
end
% Plotting errors
rms_vector = cell2mat(RMS_error);
rms_vector_test = cell2mat(RMS_error_test);
f1 = figure;
plot(order,rms_vector,'b-','LineWidth',1.5);
hold on;
plot(order,rms_vector_test,'r-','LineWidth',1.5);
title('RMS (MLE) error of trainng and test data sets vs Order');
legend('Training error','Test error');
xlabel('Order');
ylabel('RMS error');
saveas(f1,'RMSerrorMLE','png');

%% Regression with MAP
clc;
clear all;
close all;
npts = 50;
% generates data points
[x,y,t] = generateData(0,0.3,npts);
beta_MAP = 1/(0.3^2);
% order vector can be of any length.
% Enter the desired order magnitudes in the below vector.

order = [0 1 3 6 9 15];
% alpha vector can be of any length.
% Enter the desired alpha values in the below vector
alpha_MAP = [0.005 0.1];
% each of the outputs corresponding to a particular order and particular alpha are stored in cell arrays

for i = 1:length(alpha_MAP)
    for l = 1:length(order)
        X{l,i} = hypothesis_func(x,order(l));
        W_star{l,i} = zeros(order(l)+1,1);
        a = eye(order(l));
        alpha_matrix{l,i} = alpha_MAP(i)*[zeros(1,order(l)+1) ; zeros(order(l),1),a];
        W_star{l,i} = (beta_MAP*X{l,i}'*X{l,i} + alpha_matrix{l,i})\(beta_MAP*X{l,i}'*t');
        mean_MAP{l,i} = X{l,i}*W_star{l,i};
        error{l,i} = (beta_MAP/2)*(X{l,i}*W_star{l,i} - t')'*(X{l,i}*W_star{l,i} - t') + (alpha_MAP(i)/2)*W_star{l,i}'*W_star{l,i};
        RMS_error{l,i} = sqrt(2*error{l,i}/length(x));
        b = ones(length(x),1);
        f4 = figure(l);
        % plotting data values, fitted curves and the shared area of certainty.

        h = shadedErrorBar(x,mean_MAP{l,i}, (sqrt(1/beta_MAP)*b),{'b-','color','b','LineWidth',2},0);
        hold on;
        plot(x,t,'ro','MarkerSize',8,'LineWidth',1.5);
        hold off; 
        % Make it look good
        grid on;
        set(gca,'FontWeight','bold','LineWidth',1.5)
        xlabel('x')
        ylabel('t')
        title(['order = ', num2str(order(l)),'alpha = ',num2str(alpha_MAP(i))]);
        saveas(f4,sprintf('MAP%d%d',l,i),'png');
        %Test data
        npts_test = 20;
        Test_x = linspace(1,2*pi,npts_test);
        Test_t = sin(0.5*Test_x) + 0.3*randn(1,npts_test);
        Y_star_test{l,i} = Test_x(1:length(W_star{l,i}))*W_star{l,i};
        error_test{l,i} = 0.5*(Y_star_test{l,i} - Test_t')'*(Y_star_test{l,i} - Test_t');
        RMS_error_test{l,i} = sqrt(2*error_test{l,i}/length(Test_x));

        
    end
end
rms_vector = cell2mat(RMS_error);
rms_vector_test = cell2mat(RMS_error_test);
% plotting errors
for i = 1:length(alpha_MAP)
    f = figure;
    plot(order,rms_vector(:,i),'b-','LineWidth',1.5);
    hold on;
    plot(order,rms_vector_test(:,i),'r-','LineWidth',1.5);
    title(['RMS (MAP) error vs Order for alpha = ',num2str(alpha_MAP(i))]);
    xlabel('Order');
    ylabel('RMS error');
    legend('Training error','Test error');

    saveas(f,'RMSerrorMAP','png');
end
   
